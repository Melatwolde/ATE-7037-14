{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOydNyW60if6kXSa5ueA22S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melatwolde/ATE-7037-14/blob/main/Tensorflow_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor is a multidimensional array like matrix\n",
        "tensor shape is the layout or structure of the is crucial in TensorFlow as determines how the data is organized and how operations can be applied to the tensor"
      ],
      "metadata": {
        "id": "RdiQGnyLSALp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE_kiCkIQuCH",
        "outputId": "32843586-1d81-4f8b-f3a6-e1a4f16afd09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tensor = tf.constant([[2,3,4], [3,4,5]])\n",
        "shape = tensor.shape\n",
        "print(shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor size refers to the total number of elements in a tensor. It is the product of all the dimensions (sizes) of the tensor. In other words, it represents the total amount of data stored in the tensor."
      ],
      "metadata": {
        "id": "1qVAD8PdSZdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tensor = tf.constant([[2,3,4], [3,4,5]])\n",
        "size = tf.size(tensor)\n",
        "print(size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0TzZy0XRc8Z",
        "outputId": "26e3378a-28a2-4b43-f84a-102717566ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor rank**, also known as the tensor's number of dimensions, is a fundamental concept in TensorFlow. It indicates the number of dimensions present in a tensor.\n",
        "\n",
        "*Here's a brief overview of tensor rank*:\n",
        "\n",
        "\n",
        "\n",
        "* Rank 0: Scalars. Tensors of rank 0 represent single values.\n",
        "* Rank 1: Vectors. Tensors of rank 1 have one dimension and represent arrays of values.\n",
        "*Rank 2: Matrices. Tensors of rank 2 have two dimensions and represent 2D arrays of values.\n",
        "*Rank 3 and above: Tensors of rank 3 or higher have three or more dimensions and represent higher-dimensional arrays of values."
      ],
      "metadata": {
        "id": "jMEby-v2TNC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create tensors of different ranks\n",
        "scalar = tf.constant(5)  # Rank 0 tensor (scalar)\n",
        "vector = tf.constant([1, 2, 3])  # Rank 1 tensor (vector)\n",
        "matrix = tf.constant([[1, 2], [3, 4]])  # Rank 2 tensor (matrix)\n",
        "tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # Rank 3 tensor (3D)\n",
        "\n",
        "# Get the rank of tensors\n",
        "rank_scalar = tf.rank(scalar)\n",
        "rank_vector = tf.rank(vector)\n",
        "rank_matrix = tf.rank(matrix)\n",
        "rank_3d = tf.rank(tensor_3d)\n",
        "\n",
        "print('Rank of scalar:', rank_scalar.numpy())\n",
        "print('Rank of vector:', rank_vector.numpy())\n",
        "print('Rank of matrix:', rank_matrix.numpy())\n",
        "print('Rank of 3D tensor:', rank_3d.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUai8BkWTMsz",
        "outputId": "9602b67d-0bfc-4006-a4df-307c8eeec902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank of scalar: 0\n",
            "Rank of vector: 1\n",
            "Rank of matrix: 2\n",
            "Rank of 3D tensor: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Tensor Slicing"
      ],
      "metadata": {
        "id": "ZcfuaDxyvsmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "t1 =[1,2,3,4,5,6]\n",
        "s1 = tf.slice(t1, begin = [2], size = [3])\n",
        "s2 = t1[1:4] #python way of slicing\n",
        "print(s1,s2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN5WmG7Jv-XE",
        "outputId": "cfb98bc6-bfcf-4664-cd06-402da10076ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([3 4 5], shape=(3,), dtype=int32) [2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kxyBTvEvv8kK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beyond Single Dimensions:\n",
        "Slicing works for multi-dimensional tensors too! Imagine a matrix t2 of numbers:\n",
        "\n",
        "`tf.slice(t2, [0, 0], [1, tf.shape(t2)[1]])`\n",
        "\n",
        "*   `tf.slice()` is a TensorFlow function that extracts a sub-tensor from a given tensor\n",
        "*   `t2` is the input tensor (assumed to be a 2D matrix).\n",
        "*   `[0, 0]` → This is the begin argument, which specifies the starting index of the slice:\n",
        "\n",
        "*   `0` → Start from row index 0 (first row).\n",
        "\n",
        "*    `0 `→ Start from column index 0 (first column).\n",
        "\n",
        "*    `[1, tf.shape(t2)[1]]` → This is the size argument, which specifies how many elements to take along each axis:\n",
        "\n",
        "*   ` 1` → Take 1 row (i.e., only the first row).\n",
        "\n",
        "*    `tf.shape(t2)[1]` → Take all columns in the row (since tf.shape(t2)[1] gets the total number of columns in t2)."
      ],
      "metadata": {
        "id": "QwwMTA4_w1Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "t2 = tf.constant([[0, 1, 2],\n",
        "                  [3, 4, 5],\n",
        "                  [6, 7, 8]])\n",
        "\n",
        "first_row = tf.slice(t2, [0,0], [1, tf.shape(t2)[1]])\n",
        "second_row = tf.slice(t2, [1, 0], [1, tf.shape(t2)[1]])\n",
        "second_column =tf.slice(t2,[0,0],[tf.shape(t2)[0],3])\n",
        "print(second_column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHE8mZGfw406",
        "outputId": "edd922ec-5d9f-4a44-cc84-956cfc0321d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]], shape=(3, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# easy way to slice tensor"
      ],
      "metadata": {
        "id": "0jiafR9E4Jy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "t2 = tf.constant([[0, 1, 2],\n",
        "                  [3, 4, 5],\n",
        "                  [6, 7, 8]])\n",
        "first_row = t2[0:1, :]\n",
        "first_col = t2[:, 0:1]\n",
        "print(first_col)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a5dE-c4N36",
        "outputId": "61a9e6f9-8aef-4717-b417-a255519cfa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0]\n",
            " [3]\n",
            " [6]], shape=(3, 1), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.gather() `is a powerful function in TensorFlow used to extract specific elements from a tensor based on a list of indices. Think of it like picking your favorite candies from a mixed bag—you don't need them in order; you can grab any pieces you want.\n",
        "\n"
      ],
      "metadata": {
        "id": "8EpHXVH156cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "t1 = tf.constant([1,1,2,3,4,5,6,7,8])\n",
        "t2 = tf.gather(t1, indices=[0,3,4])\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNsM04PL58-v",
        "outputId": "7c21a75b-9f6e-468d-a0ea-9ac8ce632b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 3 4], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for **multi-dimensional**  Imagine a matrix t2 of numbers:"
      ],
      "metadata": {
        "id": "B383sOga6eux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "t2 = tf.constant([[0, 1, 2],\n",
        "                  [3, 4, 5],\n",
        "                  [6, 7, 8]])\n",
        "index = [0,2]\n",
        "col = tf.gather(t2 , indices= index, axis= 1)\n",
        "print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ia_6lN6muz",
        "outputId": "b081cb2e-7112-4a36-9670-28a1d97de6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 2]\n",
            " [3 5]\n",
            " [6 8]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Picking:\n",
        "Unlike tf.gather, which extracts slices along a specific axis, tf.gather_nd allows multi-dimensional indexing. This means you can retrieve elements at exact positions (coordinates) inside a multi-dimensional tensor, rather than just along rows or columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "7LjeKq_QVlih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "t3 = tf.constant([[[1, 3, 5, 7],\n",
        "                   [9, 11, 13, 15]],\n",
        "                  [[17, 19, 21, 23],\n",
        "                   [25, 27, 29, 31]]])\n",
        "Indices = [[0, 0, 0], [1, 1, 1], [1, 0, 3]]\n",
        "special_picks = tf.gather_nd(t3, indices=Indices, batch_dims=0)\n",
        "print(special_picks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVJzcZNpV4r4",
        "outputId": "dd83b0ef-ec5f-4760-a647-91e0b5fd6e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 1 27 23], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding tf.scatter_nd\n",
        "`tf.scatter_nd` is a powerful operation in TensorFlow that allows you to insert values into specific positions in a tensor, effectively \"planting\" values at desired indices.\n",
        "\n",
        "🔹 tf.scatter_nd Requires Three Inputs:\n",
        "🔹Indices (Planting map) → Specifies where to place values.\n",
        "\n",
        "🔹Values (Seed bag) → The actual values you want to insert.\n",
        "\n",
        "🔹 shape (Garden size) → The shape of the final tensor (where values will be scattered)."
      ],
      "metadata": {
        "id": "StcLdiawbIEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "array = tf.zeros_like(tf.constant([0,0,0,0,0,0,0,0]))\n",
        "index, values, shape = [[1], [3], [6]], [2,4,8],[8]\n",
        "array = tf.scatter_nd(index,values,shape)\n",
        "print(array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTi7kLgQbUjo",
        "outputId": "bb709c1e-dbdc-4dce-b107-f550d780b03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 2 0 4 0 0 8 0], shape=(8,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Reshape a Tensor in Tensorflow?\n",
        "\n"
      ],
      "metadata": {
        "id": "J2A6jCC7eSMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with a 1 dimensional\n"
      ],
      "metadata": {
        "id": "lAXRNK2CfHo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "t1 = tf.constant([[1,2,3],[4,5,6]])\n",
        "t2 = tf.reshape(t1,[6]) ## the 6 here is like order to have a length of 6 or 6 elements\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P24XK73weoCc",
        "outputId": "21de9bb1-e24a-484d-e86a-25568645ee24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with 2d tensors"
      ],
      "metadata": {
        "id": "tCraSB2LfLFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "t1 = tf.constant([[1,2,3],[4,5,6]])\n",
        "t2 = tf.reshape(t1,[2,3]) ## orders 2 row with 3 cols\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFu11GjvfUcX",
        "outputId": "d60f4c57-e4b7-41ea-c6ca-e3e9342a549e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Transposition Operations to Reshape"
      ],
      "metadata": {
        "id": "AOa7TIlqf42W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "t1 = tf.constant([[1,2,3],[4,5,6]]) #this got a shape of 2*3\n",
        "transposed_tensor = tf.transpose(t1, perm=[1, 0]) #whaen it get transposed it become 3*2\n",
        "print(transposed_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2u4HLXf8q1",
        "outputId": "974a573a-0bcd-4d7a-e9dc-1a0152daec3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training a Neural Network using Keras API in Tensorflow**"
      ],
      "metadata": {
        "id": "Ud3hHuo3hl3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "LNKvlUzdho9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c921c72-3816-4d1f-e598-917a7bd5d35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 105ms/step - accuracy: 0.7051 - loss: 0.8919 - val_accuracy: 0.9523 - val_loss: 0.1538\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 103ms/step - accuracy: 0.9512 - loss: 0.1684 - val_accuracy: 0.9759 - val_loss: 0.0793\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 105ms/step - accuracy: 0.9682 - loss: 0.1094 - val_accuracy: 0.9775 - val_loss: 0.0780\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 102ms/step - accuracy: 0.9760 - loss: 0.0832 - val_accuracy: 0.9787 - val_loss: 0.0728\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 103ms/step - accuracy: 0.9805 - loss: 0.0678 - val_accuracy: 0.9853 - val_loss: 0.0498\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 101ms/step - accuracy: 0.9828 - loss: 0.0596 - val_accuracy: 0.9860 - val_loss: 0.0509\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 102ms/step - accuracy: 0.9855 - loss: 0.0473 - val_accuracy: 0.9845 - val_loss: 0.0549\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 102ms/step - accuracy: 0.9877 - loss: 0.0422 - val_accuracy: 0.9857 - val_loss: 0.0509\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.9887 - loss: 0.0389 - val_accuracy: 0.9873 - val_loss: 0.0473\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 107ms/step - accuracy: 0.9902 - loss: 0.0310 - val_accuracy: 0.9871 - val_loss: 0.0471\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0557\n",
            "Test accuracy: 0.9868000149726868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[2], cmap='gray')\n",
        "plt.show()\n",
        "print(y_train.shape)  # Expected label (0-9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "mxATqFKZj-w4",
        "outputId": "084dc6f1-dc77-4344-d414-e6aff259211f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the dataset**:\n",
        "You need to load `x_train `and `y_train` (as well as `x_test and y_test`) using `cifar10.load_data()`. This will give you training and testing images and labels.\n",
        "\n",
        "**Preprocessing**:\n",
        "\n",
        "**Rescaling**: The CIFAR-10 images are integers in the range 0-255. Dividing them by 255.0 converts them to floating-point numbers in the range of 0 to 1, which helps with model convergence.\n",
        "\n",
        "**astype('float32')**: This ensures that the images are stored as 32-bit floating-point numbers.\n",
        "\n",
        "Shape: CIFAR-10 images are of shape 32x32 pixels and 3 color channels (RGB). After the preprocessing step, you’ll be able to print the shape of x_train, which should be (50000, 32, 32, 3) (for the 50,000 training images)."
      ],
      "metadata": {
        "id": "aboS7sc_Cci1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocess the images\n",
        "x_train, x_test = x_train.astype('float32')/255 , x_test.astype('float32')/255\n",
        "\n",
        "# Check the shape of the data\n",
        "print(x_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HHW_eJ4taa7",
        "outputId": "e6ded6bd-6327-4925-c870-ef2f79852a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.23137255 0.24313726 0.24705882]\n",
            "   [0.16862746 0.18039216 0.1764706 ]\n",
            "   [0.19607843 0.1882353  0.16862746]\n",
            "   ...\n",
            "   [0.61960787 0.5176471  0.42352942]\n",
            "   [0.59607846 0.49019608 0.4       ]\n",
            "   [0.5803922  0.4862745  0.40392157]]\n",
            "\n",
            "  [[0.0627451  0.07843138 0.07843138]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.07058824 0.03137255 0.        ]\n",
            "   ...\n",
            "   [0.48235294 0.34509805 0.21568628]\n",
            "   [0.46666667 0.3254902  0.19607843]\n",
            "   [0.47843137 0.34117648 0.22352941]]\n",
            "\n",
            "  [[0.09803922 0.09411765 0.08235294]\n",
            "   [0.0627451  0.02745098 0.        ]\n",
            "   [0.19215687 0.10588235 0.03137255]\n",
            "   ...\n",
            "   [0.4627451  0.32941177 0.19607843]\n",
            "   [0.47058824 0.32941177 0.19607843]\n",
            "   [0.42745098 0.28627452 0.16470589]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.8156863  0.6666667  0.3764706 ]\n",
            "   [0.7882353  0.6        0.13333334]\n",
            "   [0.7764706  0.6313726  0.10196079]\n",
            "   ...\n",
            "   [0.627451   0.52156866 0.27450982]\n",
            "   [0.21960784 0.12156863 0.02745098]\n",
            "   [0.20784314 0.13333334 0.07843138]]\n",
            "\n",
            "  [[0.7058824  0.54509807 0.3764706 ]\n",
            "   [0.6784314  0.48235294 0.16470589]\n",
            "   [0.7294118  0.5647059  0.11764706]\n",
            "   ...\n",
            "   [0.72156864 0.5803922  0.36862746]\n",
            "   [0.38039216 0.24313726 0.13333334]\n",
            "   [0.3254902  0.20784314 0.13333334]]\n",
            "\n",
            "  [[0.69411767 0.5647059  0.45490196]\n",
            "   [0.65882355 0.5058824  0.36862746]\n",
            "   [0.7019608  0.5568628  0.34117648]\n",
            "   ...\n",
            "   [0.84705883 0.72156864 0.54901963]\n",
            "   [0.5921569  0.4627451  0.32941177]\n",
            "   [0.48235294 0.36078432 0.28235295]]]\n",
            "\n",
            "\n",
            " [[[0.6039216  0.69411767 0.73333335]\n",
            "   [0.49411765 0.5372549  0.53333336]\n",
            "   [0.4117647  0.40784314 0.37254903]\n",
            "   ...\n",
            "   [0.35686275 0.37254903 0.2784314 ]\n",
            "   [0.34117648 0.3529412  0.2784314 ]\n",
            "   [0.30980393 0.31764707 0.27450982]]\n",
            "\n",
            "  [[0.54901963 0.627451   0.6627451 ]\n",
            "   [0.5686275  0.6        0.6039216 ]\n",
            "   [0.49019608 0.49019608 0.4627451 ]\n",
            "   ...\n",
            "   [0.3764706  0.3882353  0.30588236]\n",
            "   [0.3019608  0.3137255  0.24313726]\n",
            "   [0.2784314  0.28627452 0.23921569]]\n",
            "\n",
            "  [[0.54901963 0.60784316 0.6431373 ]\n",
            "   [0.54509807 0.57254905 0.58431375]\n",
            "   [0.4509804  0.4509804  0.4392157 ]\n",
            "   ...\n",
            "   [0.30980393 0.32156864 0.2509804 ]\n",
            "   [0.26666668 0.27450982 0.21568628]\n",
            "   [0.2627451  0.27058825 0.21568628]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.6862745  0.654902   0.6509804 ]\n",
            "   [0.6117647  0.6039216  0.627451  ]\n",
            "   [0.6039216  0.627451   0.6666667 ]\n",
            "   ...\n",
            "   [0.16470589 0.13333334 0.14117648]\n",
            "   [0.23921569 0.20784314 0.22352941]\n",
            "   [0.3647059  0.3254902  0.35686275]]\n",
            "\n",
            "  [[0.64705884 0.6039216  0.5019608 ]\n",
            "   [0.6117647  0.59607846 0.50980395]\n",
            "   [0.62352943 0.6313726  0.5568628 ]\n",
            "   ...\n",
            "   [0.40392157 0.3647059  0.3764706 ]\n",
            "   [0.48235294 0.44705883 0.47058824]\n",
            "   [0.5137255  0.4745098  0.5137255 ]]\n",
            "\n",
            "  [[0.6392157  0.5803922  0.47058824]\n",
            "   [0.61960787 0.5803922  0.47843137]\n",
            "   [0.6392157  0.6117647  0.52156866]\n",
            "   ...\n",
            "   [0.56078434 0.52156866 0.54509807]\n",
            "   [0.56078434 0.5254902  0.5568628 ]\n",
            "   [0.56078434 0.52156866 0.5647059 ]]]\n",
            "\n",
            "\n",
            " [[[1.         1.         1.        ]\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   ...\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   [0.99215686 0.99215686 0.99215686]]\n",
            "\n",
            "  [[1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]\n",
            "   ...\n",
            "   [1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]]\n",
            "\n",
            "  [[1.         1.         1.        ]\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   ...\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   [0.99607843 0.99607843 0.99607843]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.44313726 0.47058824 0.4392157 ]\n",
            "   [0.43529412 0.4627451  0.43529412]\n",
            "   [0.4117647  0.4392157  0.41568628]\n",
            "   ...\n",
            "   [0.28235295 0.31764707 0.3137255 ]\n",
            "   [0.28235295 0.3137255  0.30980393]\n",
            "   [0.28235295 0.3137255  0.30980393]]\n",
            "\n",
            "  [[0.43529412 0.4627451  0.43137255]\n",
            "   [0.40784314 0.43529412 0.40784314]\n",
            "   [0.3882353  0.41568628 0.38431373]\n",
            "   ...\n",
            "   [0.26666668 0.29411766 0.28627452]\n",
            "   [0.27450982 0.29803923 0.29411766]\n",
            "   [0.30588236 0.32941177 0.32156864]]\n",
            "\n",
            "  [[0.41568628 0.44313726 0.4117647 ]\n",
            "   [0.3882353  0.41568628 0.38431373]\n",
            "   [0.37254903 0.4        0.36862746]\n",
            "   ...\n",
            "   [0.30588236 0.33333334 0.3254902 ]\n",
            "   [0.30980393 0.33333334 0.3254902 ]\n",
            "   [0.3137255  0.3372549  0.32941177]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.13725491 0.69803923 0.92156863]\n",
            "   [0.15686275 0.6901961  0.9372549 ]\n",
            "   [0.16470589 0.6901961  0.94509804]\n",
            "   ...\n",
            "   [0.3882353  0.69411767 0.85882354]\n",
            "   [0.30980393 0.5764706  0.77254903]\n",
            "   [0.34901962 0.5803922  0.7411765 ]]\n",
            "\n",
            "  [[0.22352941 0.7137255  0.91764706]\n",
            "   [0.17254902 0.72156864 0.98039216]\n",
            "   [0.19607843 0.7176471  0.9411765 ]\n",
            "   ...\n",
            "   [0.6117647  0.7137255  0.78431374]\n",
            "   [0.5529412  0.69411767 0.80784315]\n",
            "   [0.45490196 0.58431375 0.6862745 ]]\n",
            "\n",
            "  [[0.38431373 0.77254903 0.92941177]\n",
            "   [0.2509804  0.7411765  0.9882353 ]\n",
            "   [0.27058825 0.7529412  0.9607843 ]\n",
            "   ...\n",
            "   [0.7372549  0.7647059  0.80784315]\n",
            "   [0.46666667 0.5294118  0.5764706 ]\n",
            "   [0.23921569 0.30980393 0.3529412 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.28627452 0.30980393 0.3019608 ]\n",
            "   [0.20784314 0.24705882 0.26666668]\n",
            "   [0.21176471 0.26666668 0.3137255 ]\n",
            "   ...\n",
            "   [0.06666667 0.15686275 0.2509804 ]\n",
            "   [0.08235294 0.14117648 0.2       ]\n",
            "   [0.12941177 0.1882353  0.19215687]]\n",
            "\n",
            "  [[0.23921569 0.26666668 0.29411766]\n",
            "   [0.21568628 0.27450982 0.3372549 ]\n",
            "   [0.22352941 0.30980393 0.40392157]\n",
            "   ...\n",
            "   [0.09411765 0.1882353  0.28235295]\n",
            "   [0.06666667 0.13725491 0.20784314]\n",
            "   [0.02745098 0.09019608 0.1254902 ]]\n",
            "\n",
            "  [[0.17254902 0.21960784 0.28627452]\n",
            "   [0.18039216 0.25882354 0.34509805]\n",
            "   [0.19215687 0.3019608  0.4117647 ]\n",
            "   ...\n",
            "   [0.10588235 0.20392157 0.3019608 ]\n",
            "   [0.08235294 0.16862746 0.25882354]\n",
            "   [0.04705882 0.12156863 0.19607843]]]\n",
            "\n",
            "\n",
            " [[[0.7411765  0.827451   0.9411765 ]\n",
            "   [0.7294118  0.8156863  0.9254902 ]\n",
            "   [0.7254902  0.8117647  0.92156863]\n",
            "   ...\n",
            "   [0.6862745  0.7647059  0.8784314 ]\n",
            "   [0.6745098  0.7607843  0.87058824]\n",
            "   [0.6627451  0.7607843  0.8627451 ]]\n",
            "\n",
            "  [[0.7607843  0.8235294  0.9372549 ]\n",
            "   [0.7490196  0.8117647  0.9254902 ]\n",
            "   [0.74509805 0.80784315 0.92156863]\n",
            "   ...\n",
            "   [0.6784314  0.7529412  0.8627451 ]\n",
            "   [0.67058825 0.7490196  0.85490197]\n",
            "   [0.654902   0.74509805 0.84705883]]\n",
            "\n",
            "  [[0.8156863  0.85882354 0.95686275]\n",
            "   [0.8039216  0.84705883 0.9411765 ]\n",
            "   [0.8        0.84313726 0.9372549 ]\n",
            "   ...\n",
            "   [0.6862745  0.7490196  0.8509804 ]\n",
            "   [0.6745098  0.74509805 0.84705883]\n",
            "   [0.6627451  0.7490196  0.84313726]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.8117647  0.78039217 0.70980394]\n",
            "   [0.79607844 0.7647059  0.6862745 ]\n",
            "   [0.79607844 0.76862746 0.6784314 ]\n",
            "   ...\n",
            "   [0.5294118  0.5176471  0.49803922]\n",
            "   [0.63529414 0.61960787 0.5882353 ]\n",
            "   [0.65882355 0.6392157  0.5921569 ]]\n",
            "\n",
            "  [[0.7764706  0.74509805 0.6666667 ]\n",
            "   [0.7411765  0.70980394 0.62352943]\n",
            "   [0.7058824  0.6745098  0.5764706 ]\n",
            "   ...\n",
            "   [0.69803923 0.67058825 0.627451  ]\n",
            "   [0.6862745  0.6627451  0.6117647 ]\n",
            "   [0.6862745  0.6627451  0.6039216 ]]\n",
            "\n",
            "  [[0.7764706  0.7411765  0.6784314 ]\n",
            "   [0.7411765  0.70980394 0.63529414]\n",
            "   [0.69803923 0.6666667  0.58431375]\n",
            "   ...\n",
            "   [0.7647059  0.72156864 0.6627451 ]\n",
            "   [0.76862746 0.7411765  0.67058825]\n",
            "   [0.7647059  0.74509805 0.67058825]]]\n",
            "\n",
            "\n",
            " [[[0.8980392  0.8980392  0.9372549 ]\n",
            "   [0.9254902  0.92941177 0.96862745]\n",
            "   [0.91764706 0.9254902  0.96862745]\n",
            "   ...\n",
            "   [0.8509804  0.85882354 0.9137255 ]\n",
            "   [0.8666667  0.8745098  0.91764706]\n",
            "   [0.87058824 0.8745098  0.9137255 ]]\n",
            "\n",
            "  [[0.87058824 0.8666667  0.8980392 ]\n",
            "   [0.9372549  0.9372549  0.9764706 ]\n",
            "   [0.9137255  0.91764706 0.9647059 ]\n",
            "   ...\n",
            "   [0.8745098  0.8745098  0.9254902 ]\n",
            "   [0.8901961  0.89411765 0.93333334]\n",
            "   [0.8235294  0.827451   0.8627451 ]]\n",
            "\n",
            "  [[0.8352941  0.80784315 0.827451  ]\n",
            "   [0.91764706 0.9098039  0.9372549 ]\n",
            "   [0.90588236 0.9137255  0.95686275]\n",
            "   ...\n",
            "   [0.8627451  0.8627451  0.9098039 ]\n",
            "   [0.8627451  0.85882354 0.9098039 ]\n",
            "   [0.7921569  0.79607844 0.84313726]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.5882353  0.56078434 0.5294118 ]\n",
            "   [0.54901963 0.5294118  0.49803922]\n",
            "   [0.5176471  0.49803922 0.47058824]\n",
            "   ...\n",
            "   [0.8784314  0.87058824 0.85490197]\n",
            "   [0.9019608  0.89411765 0.88235295]\n",
            "   [0.94509804 0.94509804 0.93333334]]\n",
            "\n",
            "  [[0.5372549  0.5176471  0.49411765]\n",
            "   [0.50980395 0.49803922 0.47058824]\n",
            "   [0.49019608 0.4745098  0.4509804 ]\n",
            "   ...\n",
            "   [0.70980394 0.7058824  0.69803923]\n",
            "   [0.7921569  0.7882353  0.7764706 ]\n",
            "   [0.83137256 0.827451   0.8117647 ]]\n",
            "\n",
            "  [[0.47843137 0.46666667 0.44705883]\n",
            "   [0.4627451  0.45490196 0.43137255]\n",
            "   [0.47058824 0.45490196 0.43529412]\n",
            "   ...\n",
            "   [0.7019608  0.69411767 0.6784314 ]\n",
            "   [0.6431373  0.6431373  0.63529414]\n",
            "   [0.6392157  0.6392157  0.6313726 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to [0,1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "#Split the Dataset (80% Training, 20% Testing)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g6XNgrebtaOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d3e437-e530-4fd0-bb2c-0abfa8e6e03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (40000, 32, 32, 3) (40000, 10)\n",
            "Validation set shape: (10000, 32, 32, 3) (10000, 10)\n",
            "Test set shape: (10000, 32, 32, 3) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample 4x4 grayscale image (batch_size=1, height=4, width=4, channels=1)\n",
        "image = tf.constant([[[[1], [2], [3], [0]],\n",
        "                   [[4], [5], [6], [1]],\n",
        "                   [[7], [8], [9], [2]],\n",
        "                   [[0], [1], [2], [3]]]])\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=1, kernel_size=(2, 2), strides=(1, 1), padding=\"valid\", activation=None, input_shape=(4, 4, 1)),\n",
        "    tf.keras.layers.ReLU(),  # Apply ReLU activation\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\")  # Apply max pooling\n",
        "])\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(image)\n",
        "\n",
        "# Print results\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re4Qys7ghrH1",
        "outputId": "33d51031-5050-4959-f125-f26be17b3586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[[[0.]]]], shape=(1, 1, 1, 1), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train) , (x_test,y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1,28,28,1).astype('float')/255\n",
        "x_test = x_test.reshape(-1,28,28,1).astype('float')/255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test = tf.keras.utils.to_categorical(y_train,10)\n",
        "model = Sequential([\n",
        "    Conv2D(32,(3*3), activation ='relu', input_shape = (28,28,1)),\n",
        "    MaxPooling2D(pool_size =(2,2)),\n",
        "    Flatten(),\n",
        "    Dense(32, activation = 'relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation = 'softmax')\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer = Adam(),\n",
        "              loss = 'catagorical_crossentrophy',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
        "test_loss, test_accuracy = model.evaluate(x_test,y_test)\n",
        "\n",
        "print(test_loss, test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "aRjMXFChhq7P",
        "outputId": "75d2ac73-b1d2-4e69-830d-1925572dc6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Could not interpret loss identifier: catagorical_crossentrophy",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-51ab2c877a92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'catagorical_crossentrophy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m               metrics = ['accuracy'])\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/losses/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not interpret loss identifier: {identifier}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret loss identifier: catagorical_crossentrophy"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training from my own dataset"
      ],
      "metadata": {
        "id": "-imsRF-_mv90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/drive/My Drive/Ethiopian Food Datset - Sheet1.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Extract Image URLs and Labels\n",
        "image_urls = df[\"Image URL\"].values  # Assuming images are stored as URLs\n",
        "labels = df[\"Food Name\"].values       # Labels (Convert to categorical)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX-RJZwSm5L8",
        "outputId": "74e2b1ed-9864-45e5-c0c5-57df371359aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   Food Name                                          Image URL  \\\n",
            "0     Injera  https://bittmanproject.com/wp-content/uploads/...   \n",
            "1  Shiro Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "2  Misir Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "3   Doro Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "4      Kitfo  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "\n",
            "   Calories (kcal)  Carbs (g)  Protein (g)  Fat (g)         Portion Size  \\\n",
            "0              150         30            4        1             1 Injera   \n",
            "1              200         15           10        8              1 Scoop   \n",
            "2              180         20            9        7              1 Scoop   \n",
            "3              300         10           25       15  1 Piece (Drumstick)   \n",
            "4              400          0           30       35                 100g   \n",
            "\n",
            "  Serving Unit                              Notes  \n",
            "0        Piece    Traditional Ethiopian flatbread  \n",
            "1          Cup           Made from chickpea flour  \n",
            "2          Cup             Spiced red lentil stew  \n",
            "3        Plate                 Spicy chicken stew  \n",
            "4        Plate  Raw or lightly cooked minced beef  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Preprocess the Dataset***"
      ],
      "metadata": {
        "id": "xAzhc1mQpVPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images\n",
        "def load_image(url, target_size=(28, 28)):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img = img.convert(\"L\")  # Convert to grayscale\n",
        "        img = img.resize(target_size)  # Resize to match model input\n",
        "        img_array = np.array(img).astype(\"float32\") / 255.0  # Normalize\n",
        "        return img_array\n",
        "    except:\n",
        "        return None  # Return None if image fails to load\n",
        "\n",
        "# Load images into numpy arrays\n",
        "image_data = np.array([load_image(url) for url in image_urls if load_image(url) is not None])\n",
        "\n",
        "# Reshape for CNN input (batch_size, height, width, channels)\n",
        "image_data = image_data.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Create numeric labels\n",
        "unique_labels = list(set(labels))  # Get unique food names\n",
        "label_dict = {name: i for i, name in enumerate(unique_labels)}  # Assign index to each name\n",
        "y_data = np.array([label_dict[label] for label in labels if label in label_dict])\n",
        "\n",
        "# One-hot encode labels\n",
        "y_data = to_categorical(y_data, num_classes=len(unique_labels))\n",
        "\n",
        "# Split into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check data shape\n",
        "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLj2CbW3uiHB",
        "outputId": "4d96a4cf-39f6-44bd-c6f3-258c28db27ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (6, 28, 28, 1), y_train shape: (6, 8)\n",
            "x_test shape: (2, 28, 28, 1), y_test shape: (2, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(unique_labels), activation=\"softmax\")  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W-nz-WvpUy8",
        "outputId": "3a3904ab-f07d-4add-ff78-4aa19c45b4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 2.1372 - val_accuracy: 0.0000e+00 - val_loss: 2.1082\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.0000e+00 - loss: 2.0374 - val_accuracy: 0.0000e+00 - val_loss: 2.1444\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.0000e+00 - loss: 2.0475 - val_accuracy: 0.0000e+00 - val_loss: 2.1580\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.3333 - loss: 2.0068 - val_accuracy: 0.0000e+00 - val_loss: 2.1657\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1667 - loss: 2.0856 - val_accuracy: 0.0000e+00 - val_loss: 2.1795\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.0000e+00 - loss: 2.0907 - val_accuracy: 0.0000e+00 - val_loss: 2.1937\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.1667 - loss: 2.0162 - val_accuracy: 0.0000e+00 - val_loss: 2.2081\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.1667 - loss: 2.0017 - val_accuracy: 0.0000e+00 - val_loss: 2.2313\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.3333 - loss: 1.9444 - val_accuracy: 0.0000e+00 - val_loss: 2.2456\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.3333 - loss: 1.9229 - val_accuracy: 0.0000e+00 - val_loss: 2.2669\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 2.2669\n",
            "Test Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "scrapp images online"
      ],
      "metadata": {
        "id": "gjyySH6-1roh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-chromedriver\n",
        "!pip install --upgrade selenium webdriver-manager\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN06Teq-3PLs",
        "outputId": "6d0565a3-dd10-44e2-a04d-b0056059cc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connected to cloud.r-project.org (18.1\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Waiting for headers] [Connected to r2u\r                                                                                                    \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connected to r2u.stat.illinois.edu (19\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.83)] [Connected to r2u.stat.illinois.edu (192.17.19\r                                                                                                    \rHit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.8\r                                                                                                    \rHit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.30.0)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Replace with your API key & CSE ID\n",
        "API_KEY = \"AIzaSyBp0DZBgjCjuqLP0eSvCGwOUdcUWcUbGfA\"\n",
        "CSE_ID = \"71a01b3013a43426e\"\n",
        "\n",
        "def get_google_image(food_name):\n",
        "    search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
        "    params = {\n",
        "        \"q\": f\"{food_name} Ethiopian food\",\n",
        "        \"cx\": CSE_ID,\n",
        "        \"key\": API_KEY,\n",
        "        \"searchType\": \"image\",\n",
        "        \"num\": 1\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if \"items\" in data and len(data[\"items\"]) > 0:\n",
        "            return data[\"items\"][0][\"link\"]\n",
        "        else:\n",
        "            print(f\"No images found for {food_name}\")\n",
        "            return None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching image for {food_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "try:\n",
        "    # Load the dataset\n",
        "    file_path = \"/content/drive/My Drive/Ethiopian Food Datset - Sheet1.csv\"\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Create or ensure 'Image URL' column exists\n",
        "    if 'Image URL' not in df.columns:\n",
        "        df['Image URL'] = None\n",
        "\n",
        "    # Update image URLs\n",
        "    for index, row in df.iterrows():\n",
        "        food_name = row[\"Food Name\"]\n",
        "        print(f\"Processing {index + 1}/{len(df)}: {food_name}\")\n",
        "\n",
        "        new_img_url = get_google_image(food_name)\n",
        "\n",
        "        if new_img_url:\n",
        "            # Update the DataFrame directly\n",
        "            df.loc[index, 'Image URL'] = new_img_url\n",
        "            print(f\"✅ Found image for {food_name}\")\n",
        "\n",
        "            # Save after each successful update to prevent data loss\n",
        "            df.to_csv(\"/content/drive/My Drive/Updated_Food_Dataset.csv\", index=False)\n",
        "            print(f\"💾 Progress saved...\")\n",
        "        else:\n",
        "            print(f\"❌ No valid image found for {food_name}\")\n",
        "\n",
        "        # Add a small delay\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Final save\n",
        "    df.to_csv(\"/content/drive/My Drive/Updated_Food_Dataset.csv\", index=False)\n",
        "    print(\"\\n✅ Final dataset saved successfully!\")\n",
        "\n",
        "    # Verify the save\n",
        "    verification_df = pd.read_csv(\"/content/drive/My Drive/Updated_Food_Dataset.csv\")\n",
        "    print(f\"Total rows with images: {verification_df['Image URL'].notna().sum()}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCzlwPPr1q_M",
        "outputId": "0cbb951c-3ba4-4dc4-d6d4-611fe995ef93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1/8: Injera\n",
            "✅ Found image for Injera\n",
            "💾 Progress saved...\n",
            "Processing 2/8: Shiro Wot\n",
            "✅ Found image for Shiro Wot\n",
            "💾 Progress saved...\n",
            "Processing 3/8: Misir Wot\n",
            "✅ Found image for Misir Wot\n",
            "💾 Progress saved...\n",
            "Processing 4/8: Doro Wot\n",
            "✅ Found image for Doro Wot\n",
            "💾 Progress saved...\n",
            "Processing 5/8: Kitfo\n",
            "✅ Found image for Kitfo\n",
            "💾 Progress saved...\n",
            "Processing 6/8: Gomen\n",
            "✅ Found image for Gomen\n",
            "💾 Progress saved...\n",
            "Processing 7/8: Tibs\n",
            "✅ Found image for Tibs\n",
            "💾 Progress saved...\n",
            "Processing 8/8: Fasolia\n",
            "✅ Found image for Fasolia\n",
            "💾 Progress saved...\n",
            "\n",
            "✅ Final dataset saved successfully!\n",
            "Total rows with images: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the file\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Ethiopian Food Datset - Sheet1.csv\")\n",
        "\n",
        "# Display the contents\n",
        "print(df)\n",
        "\n",
        "# To see the first few rows only\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# To see basic information about the dataset\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC7JjI_8ATLr",
        "outputId": "060b3459-aad8-4091-ae15-76e9e11bfc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Food Name                                          Image URL  \\\n",
            "0     Injera  https://bittmanproject.com/wp-content/uploads/...   \n",
            "1  Shiro Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "2  Misir Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "3   Doro Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "4      Kitfo  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "5      Gomen  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "6       Tibs  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "7    Fasolia  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "\n",
            "   Calories (kcal)  Carbs (g)  Protein (g)  Fat (g)         Portion Size  \\\n",
            "0              150         30            4        1             1 Injera   \n",
            "1              200         15           10        8              1 Scoop   \n",
            "2              180         20            9        7              1 Scoop   \n",
            "3              300         10           25       15  1 Piece (Drumstick)   \n",
            "4              400          0           30       35                 100g   \n",
            "5              100          8            5        3              1 Scoop   \n",
            "6              250          5           20       18              1 Plate   \n",
            "7              180         22            6        8              1 Scoop   \n",
            "\n",
            "  Serving Unit                                       Notes  \n",
            "0        Piece             Traditional Ethiopian flatbread  \n",
            "1          Cup                    Made from chickpea flour  \n",
            "2          Cup                      Spiced red lentil stew  \n",
            "3        Plate                          Spicy chicken stew  \n",
            "4        Plate           Raw or lightly cooked minced beef  \n",
            "5          Cup                    Ethiopian collard greens  \n",
            "6        Plate                    Grilled beef with spices  \n",
            "7          Cup  Ethiopian green beans and carrots stir-fry  \n",
            "\n",
            "First few rows:\n",
            "   Food Name                                          Image URL  \\\n",
            "0     Injera  https://bittmanproject.com/wp-content/uploads/...   \n",
            "1  Shiro Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "2  Misir Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "3   Doro Wot  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "4      Kitfo  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
            "\n",
            "   Calories (kcal)  Carbs (g)  Protein (g)  Fat (g)         Portion Size  \\\n",
            "0              150         30            4        1             1 Injera   \n",
            "1              200         15           10        8              1 Scoop   \n",
            "2              180         20            9        7              1 Scoop   \n",
            "3              300         10           25       15  1 Piece (Drumstick)   \n",
            "4              400          0           30       35                 100g   \n",
            "\n",
            "  Serving Unit                              Notes  \n",
            "0        Piece    Traditional Ethiopian flatbread  \n",
            "1          Cup           Made from chickpea flour  \n",
            "2          Cup             Spiced red lentil stew  \n",
            "3        Plate                 Spicy chicken stew  \n",
            "4        Plate  Raw or lightly cooked minced beef  \n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8 entries, 0 to 7\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Food Name        8 non-null      object\n",
            " 1   Image URL        8 non-null      object\n",
            " 2   Calories (kcal)  8 non-null      int64 \n",
            " 3   Carbs (g)        8 non-null      int64 \n",
            " 4   Protein (g)      8 non-null      int64 \n",
            " 5   Fat (g)          8 non-null      int64 \n",
            " 6   Portion Size     8 non-null      object\n",
            " 7   Serving Unit     8 non-null      object\n",
            " 8   Notes            8 non-null      object\n",
            "dtypes: int64(4), object(5)\n",
            "memory usage: 708.0+ bytes\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_27VOa-bWG3z",
        "outputId": "9d7052c0-7513-4a02-ba1c-a192db278738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google_images_download import google_images_download\n",
        "import os\n",
        "import csv\n",
        "\n",
        "def download_images(keywords, output_dir, csv_file):\n",
        "    response = google_images_download.googleimagesdownload()\n",
        "    metadata = []\n",
        "\n",
        "    for keyword in keywords:\n",
        "        arguments = {\n",
        "            \"keywords\": keyword,\n",
        "            \"limit\": 10,  # Number of images per keyword\n",
        "            \"print_urls\": True,\n",
        "            \"output_directory\": output_dir,\n",
        "            \"no_directory\": True\n",
        "        }\n",
        "        paths = response.download(arguments)\n",
        "        for img_path in paths[0][keyword]:\n",
        "            metadata.append({\"label\": keyword, \"image_path\": img_path})\n",
        "\n",
        "    # Save metadata to CSV\n",
        "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=[\"label\", \"image_path\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(metadata)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    keywords = [\"pizza\", \"burger\", \"sushi\",\"Injera\", \"Kitfo\", \"Genfo\",\"Dulet\"]  # Food categories\n",
        "    output_dir = \"images\"\n",
        "    csv_file = \"image_metadata.csv\"\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    download_images(keywords, output_dir, csv_file)\n",
        "    print(f\"Images and metadata saved to {output_dir} and {csv_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBxb5qqYWmGf",
        "outputId": "12603a58-eacb-491d-f3bd-eefbd2da25d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = pizza\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "\n",
            "Item no.: 1 --> Item name = burger\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "\n",
            "Item no.: 1 --> Item name = sushi\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "\n",
            "Item no.: 1 --> Item name = Injera\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "\n",
            "Item no.: 1 --> Item name = Kitfo\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "\n",
            "Item no.: 1 --> Item name = Genfo\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "\n",
            "Item no.: 1 --> Item name = Dulet\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "Images and metadata saved to images and image_metadata.csv\n"
          ]
        }
      ]
    }
  ]
}